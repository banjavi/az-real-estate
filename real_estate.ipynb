{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Introduction\n",
    "This notebook focuses on predicting real estate prices in Maricopa County, AZ. We will first use traditional machine learning, followed by a deep learning approach, to understand the nuances and performances of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Data Loading, Preprocessing, Exploration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After one-hot encode (51325, 79)\n",
      "Skewed Features (Before Transformation)\n",
      "HOA/MONTH             125.714698\n",
      "LOT SIZE              112.786633\n",
      "BATHS                  71.296385\n",
      "PRICE                  10.152511\n",
      "SQUARE FEET             5.823412\n",
      "BEDS                    0.634905\n",
      "LATITUDE               -0.019203\n",
      "LONGITUDE              -0.518845\n",
      "YEAR BUILT             -0.706476\n",
      "ZIP OR POSTAL CODE   -153.956455\n",
      "dtype: float64\n",
      "Skewed Features (After Transformation)\n",
      "BATHS                  1.454248\n",
      "BEDS                   0.634905\n",
      "HOA/MONTH              0.075822\n",
      "LATITUDE              -0.019203\n",
      "LOT SIZE              -0.235573\n",
      "SQUARE FEET           -0.352653\n",
      "LONGITUDE             -0.539292\n",
      "YEAR BUILT            -0.643960\n",
      "PRICE                 -0.821127\n",
      "ZIP OR POSTAL CODE   -75.742938\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# LOAD\n",
    "#----------------------------\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.DtypeWarning)\n",
    "df = pd.read_csv('data/MaricopaCounty_SampleTransactions_2020_2023.csv')\n",
    "df = df.dropna(subset=['SOLD DATE'])\n",
    "df['SOLD DATE'] = pd.to_datetime(df['SOLD DATE'])\n",
    "df['SALE_YEAR'] = df['SOLD DATE'].dt.year\n",
    "df['SALE_MONTH'] = df['SOLD DATE'].dt.month\n",
    "\n",
    "#print(df.shape) #51k records \n",
    "\n",
    "# PREPROCESSING\n",
    "#----------------------------\n",
    "drop_columns = [\"SALE TYPE\", \"ADDRESS\", \"STATE OR PROVINCE\", \"SOLD DATE\", \"DAYS ON MARKET\",\n",
    "                \"$/SQUARE FEET\", \"STATUS\", \"NEXT OPEN HOUSE START TIME\", \n",
    "                \"NEXT OPEN HOUSE END TIME\", \n",
    "                \"URL (SEE https://www.redfin.com/buy-a-home/comparative-market-analysis FOR INFO ON PRICING)\", \n",
    "                \"SOURCE\", \"MLS#\", \"FAVORITE\", \"INTERESTED\", \"LOCATION\"]\n",
    "df = df.drop(columns=drop_columns)\n",
    "\n",
    "# numeric, fill with median \n",
    "for col in df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "# categorical, fill with mode \n",
    "for col in df.select_dtypes(exclude=['float64', 'int64']).columns:\n",
    "    mode_value = df[col].mode()\n",
    "    if not mode_value.empty:\n",
    "        df[col].fillna(mode_value.iloc[0], inplace=True)\n",
    "\n",
    "# one-hot encode, easier for ML \n",
    "df = pd.get_dummies(df, columns=[\"PROPERTY TYPE\", \"CITY\"], drop_first=True)\n",
    "print(\"After one-hot encode\", df.shape) #After one-hot encode: 51k records 17K columns with location, 662 with City \n",
    "\n",
    "# split data into training, validation, and test sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.25, random_state=42)  # 0.25 * 0.8 = 0.2\n",
    "\n",
    "# EXPLORATION\n",
    "#----------------------------\n",
    "\n",
    "# NUMERIC\n",
    "# checking skewness for numeric features\n",
    "skewed_features = train_df.select_dtypes(include=['float64', 'int64']).apply(lambda x: x.skew()).sort_values(ascending=False)\n",
    "print('Skewed Features (Before Transformation)')\n",
    "print(skewed_features)\n",
    "\n",
    "# apply log1p transformation for positively skewed features\n",
    "positively_skewed = ['HOA/MONTH', 'LOT SIZE', 'BATHS', 'PRICE', 'SQUARE FEET']\n",
    "for feature in positively_skewed:\n",
    "    train_df[feature] = np.log1p(train_df[feature])\n",
    "    val_df[feature] = np.log1p(val_df[feature])\n",
    "    test_df[feature] = np.log1p(test_df[feature])\n",
    "\n",
    "# apply cube transformation for negatively skewed features\n",
    "negatively_skewed = ['LONGITUDE', 'YEAR BUILT', 'ZIP OR POSTAL CODE']\n",
    "for feature in negatively_skewed:\n",
    "    train_df[feature] = train_df[feature]**3\n",
    "    val_df[feature] = val_df[feature]**3\n",
    "    test_df[feature] = test_df[feature]**3\n",
    "\n",
    "# re-check skewness after transformations\n",
    "new_skewed_features = train_df.select_dtypes(include=['float64', 'int64']).apply(lambda x: x.skew()).sort_values(ascending=False)\n",
    "print('Skewed Features (After Transformation)')\n",
    "print(new_skewed_features)\n",
    "\n",
    "X_train = train_df.drop(columns=[\"PRICE\"])\n",
    "y_train = train_df[\"PRICE\"]\n",
    "\n",
    "X_val = val_df.drop(columns=[\"PRICE\"])\n",
    "y_val = val_df[\"PRICE\"]\n",
    "\n",
    "X_test = test_df.drop(columns=[\"PRICE\"])\n",
    "y_test = test_df[\"PRICE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Traditional Machine Learning Implementation (e.g., Linear Regression)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 100.0\n",
      "validation MAE for Linear Regression: 2283482.195000629\n",
      "validation MSE for Linear Regression: 5.134174634174195e+16\n",
      "test MAE for Linear Regression: 2531352.330071663\n",
      "test MSE for Linear Regression: 6.57754878279205e+16\n"
     ]
    }
   ],
   "source": [
    "# standardize\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# linear Regression model\n",
    "#lr = LinearRegression()\n",
    "#lr.fit(X_train, y_train)\n",
    "\n",
    "# Define alphas to test\n",
    "alphas = [0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "\n",
    "# Ridge Regression model with cross-validation\n",
    "ridge_cv = RidgeCV(alphas=alphas, store_cv_values=True)\n",
    "\n",
    "# Train the model using the training data\n",
    "ridge_cv.fit(X_train, y_train)\n",
    "\n",
    "# Print the best alpha\n",
    "print(\"Best alpha:\", ridge_cv.alpha_)\n",
    "\n",
    "\n",
    "# ridge Regression model (you can adjust the alpha parameter based on cross-validation results)\n",
    "ridge = Ridge(alpha=100)\n",
    "# train the model using the training data\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# predict on validation set and compute metrics\n",
    "y_pred_val = ridge.predict(X_val)\n",
    "mae_val = mean_absolute_error(y_val, y_pred_val)\n",
    "mse_val = mean_squared_error(y_val, y_pred_val)\n",
    "print(f\"validation MAE for Linear Regression: {mae_val}\")\n",
    "print(f\"validation MSE for Linear Regression: {mse_val}\")\n",
    "\n",
    "# predict on test set and compute metrics\n",
    "y_pred_test = ridge.predict(X_test)\n",
    "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "print(f\"test MAE for Linear Regression: {mae_test}\")\n",
    "print(f\"test MSE for Linear Regression: {mse_test}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Neural Network Implementation using Keras & TensorFlow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# design the neural network architecture\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# train the model using the training data\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val), verbose=0)\n",
    "\n",
    "# evaluate the model on the validation and test sets\n",
    "val_loss, val_mae = model.evaluate(X_val, y_val, verbose=0)\n",
    "test_loss, test_mae = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"validation MAE for Neural Network: {val_mae}\")\n",
    "print(f\"test MAE for Neural Network: {test_mae}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
